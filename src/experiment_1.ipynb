{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lbrerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Pytorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# Hydra\n",
    "import hydra\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from omegaconf import DictConfig\n",
    "from omegaconf import OmegaConf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:\n",
      "  learning_rate: 0.001\n",
      "  batch_size: 32\n",
      "  epochs: 10\n",
      "  train_dataset_dir: data/train\n",
      "  validation_dataset_dir: data/valid\n",
      "  test_dataset_dir: data/test\n",
      "data:\n",
      "  labeled_percentage: 0.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GlobalHydra.instance().clear()\n",
    "hydra.initialize(config_path=\".\", version_base=None)\n",
    "cfg = hydra.compose(config_name=\"config\")\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoader(pl.LightningDataModule):\n",
    "    def __init__(self, dataset, batch_size=32, labeled_percentage=0.3):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.labeled_percentage = labeled_percentage\n",
    "\n",
    "    def split(self):\n",
    "        total_size = len(self.dataset)\n",
    "        labeled_size = int(total_size * self.labeled_percentage)\n",
    "        unlabeled_size = total_size - labeled_size\n",
    "        self.labeled_dataset, self.unlabeled_dataset = random_split(self.dataset, [labeled_size, unlabeled_size])\n",
    "\n",
    "    def get_dataloader(self):\n",
    "        return DataLoader(self.labeled_data, batch_size=self.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (U Net Autoencoder)\n",
    "class Autoencoder(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Define las capas del encoder y del decoder con skip connections\n",
    "        self.encoder = nn.Sequential\n",
    "        (\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # Agrega más capas de encoder\n",
    "        )\n",
    "        self.decoder = nn.Sequential\n",
    "        (\n",
    "            nn.ConvTranspose2d(64, 1, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # Agrega más capas de decoder\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        reconstruction = self(x)\n",
    "        loss = nn.MSELoss()(reconstruction, x)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier_A(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(Classifier_A, self).__init__()\n",
    "        self.model = nn.Sequential\n",
    "        (\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 128),  # Ajusta según sea necesario\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.CrossEntropyLoss()(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "class Classifier_B(pl.LightningModule):\n",
    "    def __init__(self, encoder, fine_tune=False):\n",
    "        super(Classifier_B, self).__init__()\n",
    "        self.encoder = encoder\n",
    "\n",
    "        if not fine_tune:\n",
    "            for param in self.encoder.parameters():\n",
    "                param.requires_grad = False  # Congelar el encoder si es necesario\n",
    "        \n",
    "        self.classifier = nn.Sequential\n",
    "        (\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.CrossEntropyLoss()(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping \\\n",
    "(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 2546\n",
      "Testing samples: 500\n"
     ]
    }
   ],
   "source": [
    "# El dataset no redimensiona las imágenes de forma inmediata al ser cargadas en memoria. Las imágenes se cargan solo cuando accedes a ellas.\n",
    "# Las transformaciones se aplican cada vez que accedes a una imagen, no al momento de la creación del dataset. Esto significa que la imagen será\n",
    "# redimensionada solo cuando el dataset realmente cargue la imagen durante el entrenamiento o la evaluación (cuando haces una iteración sobre el dataset).\n",
    "train_full_dataset = datasets.ImageFolder(root=cfg.model.train_dataset_dir)\n",
    "test_full_dataset = datasets.ImageFolder(root=cfg.model.test_dataset_dir)\n",
    "\n",
    "train_species_counts = Counter([sample[1] for sample in train_full_dataset.samples])\n",
    "top_20_species = [species for species, count in train_species_counts.most_common(20)]\n",
    "\n",
    "train_samples_from_top_20_species_by_image_count = [sample for sample in train_full_dataset.samples if sample[1] in top_20_species]\n",
    "test_samples_from_top_20_species_by_image_count = [sample for sample in test_full_dataset.samples if sample[1] in top_20_species]\n",
    "\n",
    "train_samples = []\n",
    "test_samples = test_samples_from_top_20_species_by_image_count\n",
    "\n",
    "for specie in top_20_species:\n",
    "    species_samples = [sample for sample in train_samples_from_top_20_species_by_image_count if sample[1] == specie] # if sample tag = tag\n",
    "    random.shuffle(species_samples)\n",
    "    train_samples.extend(species_samples[:-20])\n",
    "    test_samples.extend(species_samples[-20:])\n",
    "\n",
    "print(f'Training samples: {len(train_samples)}')\n",
    "print(f'Testing samples: {len(test_samples)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose\n",
    "(\n",
    "    [\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=cfg.model.train_dataset_dir, transform=transform)\n",
    "train_dataset.samples = train_samples\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root=cfg.model.test_dataset_dir, transform=transform)\n",
    "test_dataset.samples = test_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tome el set de datos de entrenamiento y simule que una parte de cada clase no contiene\n",
    "labels, denominado set de datos sin labels, el otro restante será denominado set de datos\n",
    "con labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cl \u001b[38;5;241m=\u001b[39m \u001b[43mCustomLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m cl\u001b[38;5;241m.\u001b[39msetup()\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'dataset'"
     ]
    }
   ],
   "source": [
    "cl = CustomLoader(dataset=train_dataset, batch_size=cfg.model.batch_size, labeled_percentage=cfg.data.labeled_percentage)\n",
    "cl.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(callbacks=[early_stop_callback], max_epochs=10)\n",
    "trainer.fit(model, datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hydra.main(config_path=\".\", config_name=\"config\")\n",
    "def main(cfg: DictConfig):\n",
    "    # Aquí usas los valores de cfg para ajustar los hiperparámetros\n",
    "    print(cfg.model.lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_IC6200_AI_P2_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
